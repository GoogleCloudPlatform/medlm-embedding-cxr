{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!--\n",
        "\n",
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "-->"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JIpyR7i-XtMy"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://github.com/GoogleCloudPlatform/medlm-embedding-cxr/raw/main/intro_notebook.ipynb\">\n",
        "      <img src=\"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRQBAwQEBQQFCQUFCRQNCw0UFBQUFBQUFBQUFBQUFBQUFBQUFBQTEBQUFBQUFBAUFBQUFBQUFBQVDw8SExISDxQSDv/AABEIACAAIAMBEQACEQEDEQH/xAAZAAEAAwEBAAAAAAAAAAAAAAAGBAUHCQP/xAAsEAABBAEDAgUCBwAAAAAAAAACAQMEBREGEiEAMQcTFCIjQXEVFlFhkaHR/8QAGAEAAwEBAAAAAAAAAAAAAAAAAwQFAgb/xAApEQABAwMDBAEEAwAAAAAAAAABAgMRAAQhEjFBE1FhcSIFMpGhFIGx/9oADAMBAAIRAxEAPwDqTazVrauZLQPMWOybuzON20VXH9dFaR1XEomJIFYcVoQVdq8Km6Yso8PJg3LkRQlem35IQJE5+2VxnojzCmlKx8QSJ9VhtwLA7kTFV+o9aV1GNpFGwrfxuHWO2qQJkwWPgDKea4uFUGtybVc2qic98Y6YtrF1/QsoV01LCNQTOTwNpVGQmc0F66ba1J1DWElUExgcneBO5jFT9N2pXunauyL026ZFakL6N/z2MmCF8bmE3jzwWEymFwmel7loMPrZE/EkZEHBjIzB7icbUZlzqtJcxkA4MjPY4kdjzUi1JQq5hCRCSMmqELiNqntXsS8D917dDay4me48/rmtr+w0UmWTqC9HYenet/L5Ph6cmHD3dkIXCTaTmeyl7F7r1WQ0nC1AaepGdQ/IGQPXy4FIKWYKUkzonEfonE+8UBvm7y3v7Cvs5gP6aleHToyq+VMhsTjlEe03DIc7EUFUVcT4ULroLc2zLKHWUw6m5EKCVlGkDAAO+chJ+ZFRnEXDzqmnlS0pmCklIVqO5JG2MEj4ztWpeHUFis8PtMQ4rflRo9XFaaBZAyNoC0KInmh7XOET3DwvdOF65X6k4p29fcWZJWonBGSTwcj0cjY1fs20tWzTaBACQBmcAd+ffNWF/GnSq0wr3GQfznZIDe24P1Av2X9el7dTaHAXQY8bjzRnQtSYRv5oXaPM6iqL2tksu100qd+CdWzGAnlRQL3MlxvTHCBlEz/PVppKrZ1p5B1J1hWokxuPu3jyd/8AKnOaX0LbUIOkiIE/139UUkWUTSLtBWwWHNR3LmmmahvSzlewL+3Aqrkp3lWgx7SbUlDnOF7pXS0u8Drzh6aA6V9TUqOcITgKM5ConjxSJWm26bSBrVoCdECeMqPA4ImK0/QdZc1Om48e8ehHNHszXMeVHjN8ILLafURRMIv+dctfu27z5XbA6e6jJJ5J8mrVqh1toJeInwIA8D1SHqdTdHNdaPDWVIUUXkiTAcbdYlbVXaomJKBYUVUDQdhIhIu0lwqLhUpWF4bJ3WRKcgj2CJ5EjcSDkZBGKUubf+QjSDBEEH0Z/B2PjaDmovh14eQvD+rfbaRp+xlvuSJc0W1EnCNwjQEypFsBC2iikuERMqqqqqX6l9Rc+oOAnCUgADtAAngSYkmBnsIAxaWiLVJjKiSSfZn8DYeKW9SKer//2Q==\" alt=\"Vertex AI logo\">\n",
        "      Run in Vertex AI Workbench\n",
        "    </a>\n",
        "    </td>\n",
        "    <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/medlm-embedding-cxr/blob/main/intro_notebook.ipynb\"><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgBAMAAACBVGfHAAAALVBMVEVHcEz0mQP6rgD6rAD6rQD0mwPxjwX5qwD6qwDocArzlQP9uQDobwrobwrocAqx6FUsAAAAD3RSTlMAL4e95XEUn//k//+R/8OlcE7aAAAA0klEQVR4AcXQPwhBURQG8A/Jgt4+SCmzZDAKySiD2UBZlAkzyimLSVH2JGaZ3l5WRe97u8I+Ojf1kJ3f8nW7t3v+4Fd8iWKhBjQzxbQFoy8io3iwrDGGaoiR64tRArDYiWqKMVkBYa5HveygJZKvlve00eY5CV83KwPAv+ERBzqmkkhHwxxunELvRKAidLGkDSAkQ6goTyArAALPFsLk9wvvj7pGm+6rSkrjRsfrY7K1ECOPXqd7uneStjfLhsbpNe2BxuxtH0uSzsfGLvOrhX95AI3Oednh8+dnAAAAAElFTkSuQmCC\" alt=\"Colab logo\">\n",
        "    Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/medlm-embedding-cxr/\"><img src=\"data:image/png;base64,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\" alt=\"GitHub logo\">\n",
        "    View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Google Cloud MedLM Embedding API For CXR\n",
        "\n",
        "This notebook will ingest labeled datasets derived from a clincial imaging (PACS, VNA) system and store them in Google Cloud Healthcare API. In turn, a pre-defined cohort definition will be used to retrieve the relevant labeled images, train using embeddings created with the CXR foundation model, and ultimately deploy and test a trained model on staged data.\n",
        "\n",
        "If leveraging the sample data that is provided with the notebook, these datasets are from the [NIH Chest X-ray dataset](https://cloud.google.com/healthcare-api/docs/resources/public-datasets/nih-chest). Additionally, DICOM KOS were created to go along with the sample images.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prerequisites\n",
        "\n",
        "- Make sure you have been granted access to the MedLM Embedding API For CXR by filling out [this](https://docs.google.com/forms/d/e/1FAIpQLSd-fBqL-Ox5Qqmr6Q7nRo2oTfbttgdr700-XjSV4GEKYhbicg/viewform) form.\n",
        "- After you've been given access to the API, you only have to change the `PROJECT_ID` value below to your own project, and then you can Run All cells.\n",
        "- Code was tested with Python v3.10.6 in VSCode, Vertex AI Workbench, and Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random, sys, time, os\n",
        "import google.auth\n",
        "# Used if you run the notebook multiple times\n",
        "RAND = random.randint(1, 100000)\n",
        "\n",
        "# You must update the variables in this section\n",
        "PROJECT_ID = '[CHANGEME]'  # @param {type: 'string'}\n",
        "credentials, user = google.auth.default()\n",
        "print(f'User: {user}')\n",
        "# Local and shell consts\n",
        "os.environ['PROJECT_ID'] = PROJECT_ID\n",
        "os.environ['LOCATION'] = LOCATION = (\n",
        "    'us-central1'  # This region required for early access.\n",
        ")\n",
        "os.environ['DATASET_ID'] = DATASET_ID = 'cxr-experimental-dataset'\n",
        "os.environ['STORE_ID'] = STORE_ID = 'cxr-experimental-dicom-store'\n",
        "os.environ[\"BQ_TABLE_ID\"] = BQ_TABLE_ID = \"metadata\"\n",
        "os.environ['VERTEX_ENDPOINT_ID'] = VERTEX_ENDPOINT_ID = f'{user}-medlm-cxr-endpoint'\n",
        "os.environ['MODEL_BUCKET_NAME'] = MODEL_BUCKET_NAME = 'medlm-cxr-model-dranderson-bucket'\n",
        "os.environ['MODEL_DIR'] = MODEL_DIR = './data/outputs/model/{user}'\n",
        "\n",
        "# Local consts\n",
        "BQ_TABLE = f\"{PROJECT_ID}.{DATASET_ID}.{BQ_TABLE_ID}\"\n",
        "DICOMWEB_HOST = f'https://healthcare.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb'\n",
        "DIAGNOSIS = 'PNEUMOTHORAX'\n",
        "STAGED_DIR = './data/staged/'\n",
        "EMBEDDINGS_DIR = './data/outputs/'\n",
        "MIN_STUDIES = 195\n",
        "EMBEDDING_KEY = 'embedding'\n",
        "EMBEDDINGS_SIZE = 32 * 768  # dimensional vector\n",
        "\n",
        "# Authenticate; will only run if you're in Colab\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    # Authenticate user for access. There will be a popup asking you to sign in with your user and approve access.\n",
        "    auth.authenticate_user()\n",
        "\n",
        "# Some basic input validation\n",
        "if PROJECT_ID == '[CHANGEME]':\n",
        "    raise ValueError('Please provide your own value for PROJECT_ID')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Environment setup\n",
        "\n",
        "\n",
        "In addition to installing some local python packages, this will use Terraform to set up a [Healthcare API DICOM store](https://cloud.google.com/healthcare-api/docs/how-tos/dicom#creating_a_dicom_store), [BigQuery table](https://cloud.google.com/bigquery/docs/tables), and [streaming](https://cloud.google.com/healthcare-api/docs/how-tos/dicom-bigquery-streaming) of metadata from Healthcare API DICOM store to a BigQuery table. Additionally it will setup a Google Cloud Storage bucket to copy your model and it will create a Vertex AI Online Prediction endpoint to host the model you will eventually build."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# Get the helper code if in managed environment\n",
        "GIT_SRC_DIR=git-src\n",
        "if ! test -d scripts || ! test -d tf; then\n",
        "  git clone https://github.com/GoogleCloudPlatform/medlm-embedding-cxr.git $GIT_SRC_DIR\n",
        "  cp -rn $GIT_SRC_DIR/* . && rm -rf $GIT_SRC_DIR\n",
        "fi\n",
        "\n",
        "# Run the setup\n",
        "./scripts/simple_setup.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate embeddings for all DICOM images\n",
        "\n",
        "Call the MedLM Embedding API For CXR with a reference to each DICOM image in the Healthcare API DICOM store, generate an embedding, and store it locally for use in training later. This may take ~15 mins, depending on data being sent, your connection latency, and load on server. You may think of embeddings as compressed raster images, in a format efficient for model training.\n",
        "\n",
        "**IMPORTANT:** You must have access to use the MedLM Embedding API for CXR. For access, please fill out [this](https://docs.google.com/forms/d/e/1FAIpQLSd-fBqL-Ox5Qqmr6Q7nRo2oTfbttgdr700-XjSV4GEKYhbicg/viewform) form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.auth.transport.requests import AuthorizedSession\n",
        "from google.cloud import storage\n",
        "\n",
        "_CXR_URL = f\"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/medlm-embedding-cxr:predict\"\n",
        "\n",
        "api_session = AuthorizedSession(credentials)\n",
        "\n",
        "\n",
        "def retrieve_embedding_array(dicomUri: str) -> np.ndarray:\n",
        "    json = {\n",
        "        \"instances\": [{\"dicomUri\": dicomUri}],\n",
        "    }\n",
        "\n",
        "    while True:  # Basic retry, no limit for HTTP 429 (due to quota)\n",
        "        response = api_session.post(_CXR_URL, json=json)\n",
        "        if response.status_code == 429:\n",
        "            time.sleep(5)\n",
        "            continue\n",
        "        if not response.ok:\n",
        "            raise RuntimeError(f\"Embedding creation call failed: {response.text}\")\n",
        "        break\n",
        "\n",
        "    embed = response.json()[\"predictions\"][0][\"chestXRayEmbedding\"]\n",
        "    return np.array(embed, dtype=np.float32)\n",
        "\n",
        "\n",
        "client = storage.Client()\n",
        "bucket = client.get_bucket('cxr-experimental-training-data')\n",
        "    \n",
        "blob = bucket.get_blob('training_examples.csv')\n",
        "blob.download_to_filename('./sample_data/training_examples.csv')\n",
        "\n",
        "training_data_df = pd.read_csv(\"./sample_data/training_examples.csv\")\n",
        "\n",
        "display(training_data_df.tail())\n",
        "\n",
        "i, total = 0, len(training_data_df)\n",
        "for _, row in training_data_df.iterrows():\n",
        "    i += 1\n",
        "    if os.path.exists(row[\"embedding_file\"]):\n",
        "        print(f'[{i}/{total}] Embedding file exists; skipping: {row[\"embedding_file\"]}')\n",
        "        continue\n",
        "    dicomUri = f'{DICOMWEB_HOST}/{row[\"dicom_uri\"]}'\n",
        "    print(f'DICOM URI: {dicomUri}')\n",
        "    arr = retrieve_embedding_array(dicomUri=dicomUri)\n",
        "    example = tf.train.Example()\n",
        "    example.features.feature[EMBEDDING_KEY].float_list.value[:] = arr.flatten()\n",
        "    with tf.io.TFRecordWriter(row[\"embedding_file\"]) as w:\n",
        "        w.write(example.SerializeToString())\n",
        "\n",
        "    print(f'[{i}/{total}] Generated embedding file: {row[\"embedding_file\"]}')\n",
        "\n",
        "print(\"Completed embedding file creation\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fVGYhxEkWBhs"
      },
      "source": [
        "## Train A Model\n",
        "\n",
        "Finally, we can train a model using the embeddings! With a simple feed-forward neural network, it should take < 5 minutes to train 100 epochs! No GPU required.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_models as tfm\n",
        "from typing import Iterable\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def parse_serialized_example_values(\n",
        "    serialized_example: bytes,\n",
        ") -> tf.Tensor:\n",
        "    features = {\n",
        "        EMBEDDING_KEY: tf.io.FixedLenFeature(\n",
        "            [EMBEDDINGS_SIZE],\n",
        "            tf.float32,\n",
        "            default_value=tf.constant(0.0, shape=[EMBEDDINGS_SIZE]),\n",
        "        )\n",
        "    }\n",
        "    parsed_tensors = tf.io.parse_example(serialized_example, features=features)\n",
        "    return parsed_tensors[EMBEDDING_KEY]\n",
        "\n",
        "\n",
        "def get_dataset(filenames: Iterable[str], labels: Iterable[int]) -> tf.data.Dataset:\n",
        "    ds_embeddings = tf.data.TFRecordDataset(\n",
        "        filenames, num_parallel_reads=tf.data.AUTOTUNE\n",
        "    ).map(parse_serialized_example_values)\n",
        "    ds_labels = tf.data.Dataset.from_tensor_slices(labels)\n",
        "\n",
        "    return tf.data.Dataset.zip((ds_embeddings, ds_labels))\n",
        "\n",
        "\n",
        "def create_model(\n",
        "    heads,\n",
        "    learning_rate=0.1,\n",
        "    end_lr_factor=1.0,\n",
        "    dropout=0.0,\n",
        "    decay_steps=1000,\n",
        "    loss_weights=None,\n",
        "    hidden_layer_sizes=[512, 256],\n",
        "    weight_decay=0.0,\n",
        "    seed=None,\n",
        ") -> tf.keras.Model:\n",
        "    # Creates linear probe or multilayer perceptron using LARS + cosine decay.\n",
        "    inputs = tf.keras.Input(shape=(32 * 768,))  # Based on ELIXR\n",
        "    inputs_reshape = tf.keras.layers.Reshape((32, 768))(inputs)\n",
        "    inputs_pooled = tf.keras.layers.GlobalAveragePooling1D(data_format=\"channels_last\")(\n",
        "        inputs_reshape\n",
        "    )\n",
        "    hidden = inputs_pooled\n",
        "    # If no hidden_layer_sizes are provided, model will be a linear probe.\n",
        "    for size in hidden_layer_sizes:\n",
        "        hidden = tf.keras.layers.Dense(\n",
        "            size,\n",
        "            activation=\"relu\",\n",
        "            kernel_initializer=tf.keras.initializers.HeUniform(seed=seed),\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2=weight_decay),\n",
        "            bias_regularizer=tf.keras.regularizers.l2(l2=weight_decay),\n",
        "        )(hidden)\n",
        "        hidden = tf.keras.layers.BatchNormalization()(hidden)\n",
        "        hidden = tf.keras.layers.Dropout(dropout, seed=seed)(hidden)\n",
        "    output = tf.keras.layers.Dense(\n",
        "        units=len(heads),\n",
        "        activation=\"sigmoid\",\n",
        "        kernel_initializer=tf.keras.initializers.HeUniform(seed=seed),\n",
        "    )(hidden)\n",
        "\n",
        "    outputs = {}\n",
        "    for i, head in enumerate(heads):\n",
        "        outputs[head] = tf.keras.layers.Lambda(\n",
        "            lambda x: x[..., i : i + 1], name=head.lower()\n",
        "        )(output)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    learning_rate_fn = tf.keras.experimental.CosineDecay(\n",
        "        tf.cast(learning_rate, tf.float32),\n",
        "        tf.cast(decay_steps, tf.float32),\n",
        "        alpha=tf.cast(end_lr_factor, tf.float32),\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=tfm.optimization.lars.LARS(learning_rate=learning_rate_fn),\n",
        "        loss=dict([(head, \"binary_crossentropy\") for head in heads]),\n",
        "        loss_weights=loss_weights or dict([(head, 1.0) for head in heads]),\n",
        "        weighted_metrics=[\n",
        "            tf.keras.metrics.FalsePositives(),\n",
        "            tf.keras.metrics.FalseNegatives(),\n",
        "            tf.keras.metrics.TruePositives(),\n",
        "            tf.keras.metrics.TrueNegatives(),\n",
        "            tf.keras.metrics.AUC(),\n",
        "            tf.keras.metrics.AUC(curve=\"PR\", name=\"auc_pr\"),\n",
        "        ],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "# Create train and validation split (train = 70%, validation = 30%)\n",
        "df_train, df_validate = train_test_split(training_data_df, train_size=0.7)\n",
        "\n",
        "# Create training and validation datasets\n",
        "training_data = get_dataset(\n",
        "    filenames=df_train[\"embedding_file\"].values, labels=df_train['label'].values\n",
        ")\n",
        "\n",
        "\n",
        "validation_data = get_dataset(\n",
        "    filenames=df_validate[\"embedding_file\"].values, labels=df_validate['label'].values\n",
        ")\n",
        "\n",
        "# Create and train the model\n",
        "model = create_model([DIAGNOSIS])\n",
        "\n",
        "model.fit(\n",
        "    x=training_data.batch(512).prefetch(tf.data.AUTOTUNE).cache(),\n",
        "    validation_data=validation_data.batch(1).cache(),\n",
        "    epochs=100,\n",
        ")\n",
        "\n",
        "# Summary after training is complete\n",
        "model.summary()\n",
        "\n",
        "# Save the model locally\n",
        "tf.saved_model.save(model, MODEL_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Examine metrics\n",
        "\n",
        "Graph the metrics for the model based on validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rows = []\n",
        "for embeddings, label in validation_data.batch(1):\n",
        "    row = {\n",
        "        f\"{DIAGNOSIS}_prediction\": model(embeddings)[DIAGNOSIS].numpy().flatten()[0],\n",
        "        f\"{DIAGNOSIS}_value\": label.numpy().flatten()[0],\n",
        "    }\n",
        "    rows.append(row)\n",
        "eval_df = pd.DataFrame(rows)\n",
        "eval_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import sklearn\n",
        "\n",
        "\n",
        "def plot_curve(x, y, auc, x_label=None, y_label=None, label=None):\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  plt.plot(x, y, label=f'{label} (AUC: %.3f)' % auc, color='black')\n",
        "  plt.legend(loc='lower right', fontsize=18)\n",
        "  plt.xlim([-0.01, 1.01])\n",
        "  plt.ylim([-0.01, 1.01])\n",
        "  if x_label:\n",
        "    plt.xlabel(x_label, fontsize=24)\n",
        "  if y_label:\n",
        "    plt.ylabel(y_label, fontsize=24)\n",
        "  plt.xticks(fontsize=12)\n",
        "  plt.yticks(fontsize=12)\n",
        "  plt.grid(visible=True)\n",
        "\n",
        "labels = eval_df[f'{DIAGNOSIS}_value'].values\n",
        "predictions = eval_df[f'{DIAGNOSIS}_prediction'].values\n",
        "false_positive_rate, true_positive_rate, thresholds = sklearn.metrics.roc_curve(\n",
        "    labels,\n",
        "    predictions,\n",
        "    drop_intermediate=False)\n",
        "auc = sklearn.metrics.roc_auc_score(labels, predictions)\n",
        "plot_curve(false_positive_rate, true_positive_rate, auc, x_label='False Positive Rate', y_label='True Positive Rate', label=DIAGNOSIS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy the model and test it\n",
        "The following section shows how to deploy the exported model to GCP and then test inference by creating the embeddings API and then online prediction endpoint where your model is hosted.\n",
        "\n",
        "**NOTE**: The deployment of the model to the endpoint could take ~15 mins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!./scripts/deploy_model.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run predictions on images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import pydicom\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_MY_MODEL_URL = f\"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{VERTEX_ENDPOINT_ID}:predict\"\n",
        "\n",
        "\n",
        "def get_online_prediction(instance):\n",
        "    # Call CXR to generate embeddings\n",
        "    input = retrieve_embedding_array(dicomUri=instance)\n",
        "    json = { \"instances\": input.reshape(1, EMBEDDINGS_SIZE).tolist() }\n",
        "    # Call my model with the embedding and get prediction\n",
        "    response = api_session.post(_MY_MODEL_URL, json=json)\n",
        "    if not response.ok:\n",
        "        raise RuntimeError(f\"Prediction call failed: {response.content}\")\n",
        "    res = response.json()\n",
        "    return res\n",
        "\n",
        "# Postive prediction\n",
        "pos_file = STAGED_DIR + \"positive.dcm\"\n",
        "pos_instance = f'{DICOMWEB_HOST}/studies/1.3.6.1.4.1.11129.5.5.125244073909057181345738889085284198099651/series/1.3.6.1.4.1.11129.5.5.138502690012449501224934835894513332244191/instances/1.3.6.1.4.1.11129.5.5.144821354400097386866710469118057421849850'\n",
        "pos_predict = get_online_prediction(pos_instance)\n",
        "\n",
        "# Negative prediction\n",
        "neg_file = STAGED_DIR + \"negative.dcm\"\n",
        "neg_instance = f'{DICOMWEB_HOST}/studies/1.3.6.1.4.1.11129.5.5.195421166273048982066192993508222383663074/series/1.3.6.1.4.1.11129.5.5.131098996341768723770121426857691412090508/instances/1.3.6.1.4.1.11129.5.5.164778748062349548634537702002731919155437'\n",
        "neg_predict = get_online_prediction(neg_instance)\n",
        "\n",
        "# Display images\n",
        "_, axes = plt.subplots(1, 2, figsize=(15, 15))\n",
        "axes[0].imshow(pydicom.dcmread(pos_file).pixel_array, cmap='gray')\n",
        "axes[0].set_title(f\"\\\"Positive\\\" {DIAGNOSIS.lower()} prediction: {pos_predict['predictions'][0][0]:.3f}\")\n",
        "axes[0].set_axis_off()\n",
        "axes[1].imshow(pydicom.dcmread(neg_file).pixel_array, cmap='gray')\n",
        "axes[1].set_title(f\"\\\"Negative\\\" {DIAGNOSIS.lower()} prediction: {neg_predict['predictions'][0][0]:.3f}\")\n",
        "axes[1].set_axis_off();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup resources\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "!rm ./data/outputs/*.tfrecord\n",
        "# TODO[JK]: Remove model from endpoint before destroy\n",
        "# Uncomment to destroy resources (default=OFF for Run All)\n",
        "# ./terraform -chdir=./tf destroy -auto-approve"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "8LpEO7UrU9eS"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "d3ac608b8f9188be2227ae82298dfd5de684cbdc4496f362d4b3b9040509447c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
